# Copyright 2017 Jeff Foley. All rights reserved.
# Use of this source code is governed by Apache 2 LICENSE that can be found in the LICENSE file.

# Should only passive data sources be used without DNS resolution?
#mode = passive
# Would you like to use more active techniques, such as pulling
# certificates from discovered IP addresses?
#mode = active

# The directory that stores the Cayley graph database and other output files
# The default for Linux systems is: $HOME/.config/amass
#output_directory = amass

# An additional directory for scripts to be provided by the user
#scripts_directory = 

# The maximum number of concurrent DNS queries that can be performed during the enumeration.
#maximum_dns_queries = 20000

[scope]
# Single IP address or range (e.g. a.b.c.10-245)
#address = 192.168.1.1
#cidr = 192.168.1.0/24
#asn = 26808
#port = 80
port = 443
#port = 8080

# Root domain names used in the enumeration
#[scope.domains]
#domain = owasp.org
#domain = appsecusa.org
#domain = appsec.eu
#domain = appsec-labs.com

# Are there any subdomains that are out of scope?
#[scope.blacklisted]
#subdomain = education.appsec-labs.com
#subdomain = 2012.appsecusa.org

# DNS resolvers used globally by the amass package
#[resolvers]
#monitor_resolver_rate = true
#resolver = 1.1.1.1 ; Cloudflare
#resolver = 8.8.8.8 ; Google
#resolver = 64.6.64.6 ; Verisign
#resolver = 74.82.42.42 ; Hurricane Electric
#resolver = 1.0.0.1 ; Cloudflare Secondary
#resolver = 8.8.4.4 ; Google Secondary
#resolver = 64.6.65.6 ; Verisign Secondary
#resolver = 77.88.8.1 ; Yandex.DNS Secondary

# Are there any data sources that should not be utilized?
#[disabled_data_sources]
#data_source = Ask
#data_source = Exalead
#data_source = IPv4Info

# Specify which graph database is the primary db, or the local database will be selected.
[graphdbs]
#local_database = false

# postgres://[username:password@]host[:port]/database-name?sslmode=disable of the PostgreSQL 
# database and credentials. Sslmode is optional, and can be disable, require, verify-ca, or verify-full.
[graphdbs.postgres]
primary = true
url = "postgres://[username:password@]host[:port]/database-name?sslmode=disable"
options="connect_timeout=10"

# [username:password@]tcp(host[:3306])/database-name of the MqSQL database and credentials.
#[graphdbs.mysql]
#url = [username:password@]tcp(host[:3306])/database-name

# Configure Amass to use a TinkerPop Server as the graph database
# For an example of Gremlin settings see: https://docs.microsoft.com/en-us/azure/cosmos-db/create-graph-gremlin-console
#[graphdbs.gremlin]
#url = wss://localhost:8182
#username =
#password =

# Settings related to brute forcing
#[bruteforce]
#enabled = true
#recursive = true
# Number of discoveries made in a subdomain before performing recursive brute forcing
# Default is 1
#minimum_for_recursive = 1
#wordlist_file = /usr/share/wordlists/all.txt
#wordlist_file = /usr/share/wordlists/all.txt # multiple lists can be used

# Would you like to permute resolved names?
#[alterations]
#enabled = true
# edit_distance specifies the number of times a primitive edit operation will be
# performed on a name sample during fuzzy label searching
#edit_distance = 1
#flip_words = true   # test-dev.owasp.org -> test-prod.owasp.org
#flip_numbers = true # test1.owasp.org -> test2.owasp.org
#add_words = true    # test.owasp.org -> test-dev.owasp.org
#add_numbers = true  # test.owasp.org -> test1.owasp.org
#wordlist_file = /usr/share/wordlists/all.txt
#wordlist_file = /usr/share/wordlists/all.txt # multiple lists can be used

[data_sources]
minimum_ttl = 1440

# Provide API key information for a data source
#[data_sources.AlienVault]
#apikey =

#[data_sources.BinaryEdge]
#apikey =
#ttl = 10080

#[data_sources.BufferOver]
#ttl = 10080

#[data_sources.BuiltWith]
#ttl = 10080

#[data_sources.C99]
#apikey=
#ttl = 4320

#[data_sources.Censys]
#apikey =
#secret =
#ttl = 10080

#[data_sources.Chaos]
#apikey=
#ttl = 4320

#[data_sources.Cloudflare]
#apikey=

#[data_sources.CIRCL]
#username =
#password =

#[data_sources.DNSDB]
#apikey =

#[data_sources.DNSTable]
#ttl = 4320

#[data_sources.FacebookCT]
#apikey=
#secret=
#ttl = 4320

#[data_sources.GitHub]
#apikey =
#ttl = 4320

#[data_sources.HackerOne]
#ttl = 4320

#[data_sources.HackerTarget]
#ttl = 4320

#[data_sources.NetworksDB]
#apikey =

#[data_sources.PassiveTotal]
#username =
#apikey =
#ttl = 10080

#[data_sources.RapidDNS]
#ttl = 4320

#[data_sources.Riddler]
#ttl = 4320

#[data_sources.SecurityTrails]
#apikey =
#ttl = 1440

#[data_sources.Shodan]
#apikey =
#ttl = 10080

#[data_sources.SiteDossier]
#ttl = 4320

#[data_sources.Spyse]
#apikey =
#ttl = 4320

# Provide your Twitter App Consumer API key and Consumer API secrety key
#[data_sources.Twitter]
#apikey =
#secret =

# The apikey must be an API access token created through the Investigate management UI
#[data_sources.Umbrella]
#apikey =

# URLScan can be used without an API key, but the key allows new submissions to be made
#[data_sources.URLScan]
#apikey =

#[data_sources.VirusTotal]
#apikey =
#ttl = 10080

#[data_sources.WhoisXML]
#apikey= 

#[data_sources.ZETAlytics]
#apikey=
#ttl = 1440
